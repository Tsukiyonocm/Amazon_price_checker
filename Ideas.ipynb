{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Price Checker Updates Needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "~~1. First thing I will need to do is figure out how to store all of my links for it to check. I will also need to write a loop in order for the code to check each URL accordingly and compare it to the target price.~~\n",
    "\n",
    "\n",
    "~~2. I will need to figure out a way to save each value, thinking maybe in a list, that has the Title, Price, and Link saved for each item. This is needed really so I can send myself just one email and not to send myself multiple emails during the time set needed.~~\n",
    "\n",
    "\n",
    "~~3. I will also need to figure out how to change the email settings in order to autoload the next link, instead of hard coding the link into the body. Since I am trying to check multiple items, hard coding would not work.~~\n",
    "\n",
    "\n",
    "4. Look into shortening the URLs by breaking apart the pieces that are redundent and just rebuilding the URLs when needed in the code. This would save a lot of space and make the overall code base look a bit nicer. Also look into a better way to store the snippets of code we do need to get. This will play a bit in the future as well as the database or JSON would be needed to change this to a tracker later on.\n",
    "\n",
    "\n",
    "5. Look into sqlite for overall database needs\n",
    "\n",
    "\n",
    "6. Look into using scrapy and selenium to further this project to other wishlists, and maybe fixing the issue with the missing books I ran into also?\n",
    "\n",
    "\n",
    "7. Eventually I would like a user prompt to add future wishlist items to the code base. Basically I want the code to start by asking: \n",
    "\"Would you like to update the wishlist tracker or run the tracker? yes or no\"\n",
    "\n",
    "    Once a choice is chosen, it does the subsequent process. For instance, if I add a new wishlist item, the first thing it would do is break it apart into its subsequent parts, store them in the correct lists or dictionaries (or however it is stored in the database), it would then run the program and start tracking the new values (while updating everything else).\n",
    "\n",
    "    This would also likely need the time/date added to things also, so will need to research how to better utilize that.\n",
    "    \n",
    "8. Eventually I would like this to run at set times throughout the day. I am thinking maybe once every 6 hours or so. While I know how to do this in basic from the tutorial, with all the additional changes I have made I will likely need to update a lot of the code to accomadate this.\n",
    "\n",
    "~~9. Setup a simple config file in so I do not need to remember to comment out my password before posting code updates to github. This will also need to be added to the gitignore file as well.~~\n",
    "\n",
    "\n",
    "10. Its possible that all items on the website uses the same class for its price, a-color-price. I am curious if I could reform my scraping code in order to look for this class, instead of the ID that I am currently using to find them, kindle-price. If this can be done, it would save me a good bit of code lines since I wouldnt need to create seperate variables in order to find all the prices inside of list. (Though I might still need to have seperate lists because of breaking the lists down to save space)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Some of the books are not listed under the same conditions as my regular kindle books. \n",
    "This seems to mostly apply to Textbooks, but would likely also be a problem for regular \n",
    "books and items as well. I need to look into this further.\n",
    "\n",
    "\n",
    "2. For the URLs, some of the links are not the same as the other links. I might have to eventually create multiple copies of the various code bits that are the same in order to build them upon request. Or, I might have the majority of them build when executed, and just have a misc list of full URLs that I cant break down for whatever reason.\n",
    "\n",
    "\n",
    "3. New thoughts on looking for the class. Glancing through the HTML on amazons page, it looks like the class a-color-price is used at multiple points in the document. This could cause trouble for my code overall, but I am wondering if its something that can be used anyway since .find() looks only for the first instance, and it appears the price I am looking for IS the first instance. I will need to research this more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-10-21\n",
    "- Added a config.py file to my file tree.\n",
    "- Updated gitignore to not upload my config file to my github account. So my password is only stored locally.\n",
    "\n",
    "\n",
    "4-7-21\n",
    "- Updated the github to ignore this file. Largely because I needed a place to hide my google apps password for the time. I can maybe add a better solution later.\n",
    "\n",
    "- Added a build_email() function in order to seperate the build process for the message body. It was getting to long as I added some new code to add a message to beginning of the email if there was no new items in the price range or if there was.\n",
    "\n",
    "- Updated generally readability by adding some spaces and comments for some functions on what is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thought 1: I have ran into a block with scraping the HREFs from my wishlist. I have tried Scrapy to no success, and it appears at least as of now, that the issues lies in how amazon loads the pages details. However it is done, it appears it might have to do with the fact that beautiful cant see things that are loaded up after the initial page loads. I imagine that this can be fixed, but I have spent a bit of time with no success and want to move on for now. \n",
    "\n",
    "I believe I shall move on to getting things attached to the database for now. Once attached to a database, I can move on to adding the user input in order to add more links to the page which will be a bit quciker for me anyway. In addition, once I get the database, I can move on to figuring out the solutions for additional books that currently dont work within the basics of my program as it is. \n",
    "\n",
    "I would like to get an option to scrap my entire wishlist at some point in the future, but for the time being, I shall put this in the back burner for the sake of moving on.\n",
    "\n",
    "Thought 2: For personal use, I could turn this into a full on assisstant given enough time. In addition to the checklist/tracker, I could program in a to-do list, a calender, and basically anything else I wanted. This could be a full on personal assisstant that saves me money also.\n",
    "\n",
    "\n",
    "#### Steps for Setting up Database\n",
    "1. Setup .py file for project\n",
    "2. Import sqlite3\n",
    "3. Connect the database to the file\n",
    "4. Connect Cursor\n",
    "5. Connect Table (look into docstring setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other types of books URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class = header-price a-color-price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
